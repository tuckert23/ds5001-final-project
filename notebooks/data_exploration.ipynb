{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Data Exploration\n",
    "## DS 5001\n",
    "### Author: Taylor Tucker\n",
    "\n",
    "\n",
    "In this document, separate from `data_processing.ipynb`, I will be using the various techniques we have learned in order to analyze the given data. This notebook can be considered an extension of the aforementioned notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = [\"text_num\", \"paragraph_num\", \"sentence_num\", \"token_num\"]\n",
    "TOKS = OHCO[:4]\n",
    "SENTS = OHCO[:3]\n",
    "PARAS = OHCO[:2]\n",
    "TEXTS = OHCO[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC = pd.read_csv('../data/processed/DOC.csv', index_col=0)\n",
    "DOC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = pd.read_csv(\"../data/processed/LIB.csv\", index_col=0)\n",
    "LIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_TFIDF = pd.read_csv(\"../data/processed/TOKEN_TFIDF.csv\", index_col=0)\n",
    "TOKEN_TFIDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_TFIDF = pd.read_csv(\"../data/processed/VOCAB_TFIDF.csv\")\n",
    "VOCAB_TFIDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI: Explore the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Cluster Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Document-Pair Matrix\n",
    "PAIRS = pd.DataFrame(index=pd.MultiIndex.from_product([DOC.index.tolist(), DOC.index.tolist()])).reset_index()\n",
    "PAIRS = PAIRS[PAIRS.level_0 < PAIRS.level_1].set_index([\"level_0\", \"level_1\"])\n",
    "PAIRS.index.names = [\"doc_a\", \"doc_b\"]\n",
    "PAIRS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = pd.read_csv(\"../data/processed/TFIDF.csv\").set_index(\"text_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"euclidean\", \"cosine\", \"jaccard\", \"minkowski\"]\n",
    "\n",
    "for method in methods:\n",
    "    PAIRS[method] = pdist(TFIDF, method)\n",
    "\n",
    "PAIRS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hca(sims, linkage_method='ward', color_thresh=.3, figsize=(10, 10)):\n",
    "    tree = sch.linkage(sims, method=linkage_method)\n",
    "    labels = DOC[\"title\"].values\n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(figsize=figsize)\n",
    "    dendrogram = sch.dendrogram(tree, \n",
    "                                labels=labels, \n",
    "                                orientation=\"left\", \n",
    "                                count_sort=True,\n",
    "                                distance_sort=True,\n",
    "                                above_threshold_color='.75',\n",
    "                                color_threshold=color_thresh)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hca(PAIRS[\"jaccard\"], color_thresh=10, figsize=(100, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_sorted = LIB.sort_values(\"pub_year\", ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "disp_fig = nltk.draw.dispersion_plot(TOKEN_TFIDF[\"term_str\"].to_list(), [\"computer\", \"analog\", \"digital\"], title=\"Ocurrences of Key Words in Corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table `TOKEN_TFIDF` is sorted by year, so this gives us a good representation of usage over time. It is interesting to note that the use of \"computer\" almost seems to come in waves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_year = TOKEN_TFIDF[TOKEN_TFIDF[\"term_str\"] == \"computer\"].merge(LIB, on=\"text_num\")[[\"term_str\", \"pub_year\", \"sentiment\"]].reset_index().drop(\"text_num\", axis=1).groupby(\"pub_year\").agg({'term_str': ['count'], 'sentiment': ['mean']})\n",
    "comp_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_year.columns = [\"count\", \"mean_sentiment\"]\n",
    "comp_year[\"rolling_count\"] = comp_year[\"count\"].rolling(window=3, center=True).mean()\n",
    "comp_year[\"rolling_sentiment\"] = comp_year[\"mean_sentiment\"].rolling(window=3, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-paper')\n",
    "ax1 = sns.lineplot(comp_year, x=\"pub_year\", y=\"rolling_count\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(comp_year, x=\"pub_year\", y=\"rolling_sentiment\", color=\"orange\")\n",
    "ax2.set_ylabel(\"Sentiment\")\n",
    "\n",
    "plt.title(\"Smoothed Average Sentiment and Occurances of 'Computer' over Time\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = pd.read_csv(\"../data/processed/coords.csv\")\n",
    "n_samples = 1000\n",
    "coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = coords.set_index(\"term_str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_vec = coords.loc[\"computer\", :]\n",
    "sample_coords = coords.sample(n_samples, random_state=1819).reset_index()\n",
    "sample_coords.iloc[-1] = [\"computer\"] + comp_vec.to_list()\n",
    "sample_coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.array([np.array(sample_coords.iloc[i, 1:].to_list(), dtype=\"float32\") for i in range(sample_coords.shape[0])], dtype=\"float32\")\n",
    "\n",
    "\n",
    "tsne = TSNE(perplexity=50, n_components=2, init=\"pca\", n_iter=2000, random_state=1819)\n",
    "\n",
    "tsne_values = tsne.fit_transform(vecs)\n",
    "\n",
    "sample_coords[\"x\"] = tsne_values[:, 0]\n",
    "sample_coords[\"y\"] = tsne_values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"black\" for _ in range(sample_coords.shape[0]-1)] + [\"red\"]\n",
    "sample_coords[\"color\"] = colors\n",
    "sample_coords.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_fig = px.scatter(sample_coords, \"x\", \"y\", text=\"term_str\", height=1000).update_traces(mode=\"text\", textfont_color=colors)\n",
    "tsne_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_fig.write_image(\"../media/tsne_official.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_PCA = pd.read_csv(\"../data/processed/TOKEN_PCA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pcas(token_pca, pc1, pc2, discrete_text=False):\n",
    "    if discrete_text:\n",
    "        token_pca[\"text_num\"] = token_pca[\"text_num\"].astype(\"str\")\n",
    "    else:\n",
    "        token_pca[\"text_num\"] = token_pca[\"text_num\"].astype(\"int\")\n",
    "\n",
    "    pc1 = \"PC\" + str(pc1)\n",
    "    pc2 = \"PC\" + str(pc2)\n",
    "    fig = px.scatter(token_pca, pc1, pc2, color=\"text_num\", hover_name=\"term_str\", range_x=(-0.2, 0.2), range_y=(-0.1, 0.1))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(TOKEN_PCA, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcas(TOKEN_PCA, 5, 8, discrete_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salex = pd.read_csv(\"../data/salex/salex_nrc.csv\")\n",
    "salex.columns = [col.replace(\"nrc_\", \"\") for col in salex.columns]\n",
    "salex[\"polarity\"] = salex[\"positive\"] - salex[\"negative\"]\n",
    "salex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.merge(LIB.reset_index(), TOKEN_TFIDF.reset_index(), how=\"inner\", on=\"text_num\")\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.merge(articles, salex, on=\"term_str\", how=\"left\")\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[salex.columns].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_cols = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust', 'polarity']\n",
    "articles = articles.drop([\"author\", \"pub_year\", \"pub_mon\", \"pub_day\", \"pos_tuple\", 'lemma', 'sentiment', 'term_id', 'tfidf_sum', \"negative\", \"positive\", \"title\"], axis=1)\n",
    "articles[emotion_cols] = articles[emotion_cols].fillna(0.0)\n",
    "articles = articles.set_index(SENTS)\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-paper')\n",
    "articles[emotion_cols].mean().sort_values().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_word(x):\n",
    "    if \"computer\" in str(x[\"term_str\"]):\n",
    "        val = 2\n",
    "    else:\n",
    "        val = int(np.sign(x[\"polarity\"]))\n",
    "\n",
    "    ts = x[\"token_str\"]\n",
    "\n",
    "    return \"<span class='sent{}'>{}</span>\".format(val, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles[\"html\"] = articles.apply(lambda x: \"<span class='sent{}'>{}</span>\".format(int(np.sign(x[\"polarity\"])), x.token_str), 1)\n",
    "articles[\"html\"] = articles.apply(lambda x: class_word(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = articles.groupby(SENTS)[emotion_cols].mean()\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents[\"sent_str\"] = articles.groupby(SENTS)[\"term_str\"].apply(lambda x: x.str.cat(sep=\" \"))\n",
    "sents['html_str'] = articles.groupby(SENTS)[\"html\"].apply(lambda x: x.str.cat(sep=' '))\n",
    "\n",
    "def sample_sentences(df, emo=\"polarity\"):\n",
    "    rows = []\n",
    "    for idx in df.sample(10).index:\n",
    "\n",
    "        valence = round(df.loc[idx, emo], 4)  \n",
    "        word = df.loc[idx, \"html_str\"]   \n",
    "        t = 0\n",
    "        if valence > t: color = '#ccffcc'\n",
    "        elif valence < t: color = '#ffcccc'\n",
    "        # elif \"computer\" in word: color = \"#ffff66\"\n",
    "        else: color = '#f2f2f2'\n",
    "        z=0\n",
    "        rows.append(\"\"\"<tr style=\"background-color:{0};padding:.5rem 1rem;font-size:110%;\">\n",
    "        <td>{1}</td><td>{3}</td><td width=\"400\" style=\"text-align:left;\">{2}</td>\n",
    "        </tr>\"\"\".format(color, valence, word, idx))\n",
    "\n",
    "    display(HTML('<style>#sample1 td{font-size:120%;vertical-align:top;} .sent-1{color:red;font-weight:bold;} .sent1{color:green;font-weight:bold;} .sent2{color:yellow;font-weight:bold;}</style>'))\n",
    "    display(HTML('<table id=\"sample1\"><tr><th>Sentiment</th><th>ID</th><th width=\"600\">Sentence</th></tr>'+''.join(rows)+'</table>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Article Sentiment over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_yrs = pd.merge(articles, LIB, how=\"inner\", on=\"text_num\")\n",
    "articles_yrs = articles_yrs[[\"term_str\", \"pub_year\"] + emotion_cols]\n",
    "articles_yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_sentiment_time(df, emo=\"polarity\", rolling=False, rolling_val=3):\n",
    "    gd = df.groupby(\"pub_year\")[emo].mean().reset_index()\n",
    "\n",
    "    if rolling:\n",
    "        gd[emo] = gd[emo].rolling(window=rolling_val, center=True).mean()\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    fig = sns.lineplot(gd, x=\"pub_year\", y=emo)\n",
    "    fig.set_title(\"Emotion over Time\")\n",
    "    fig.set_xlabel(\"Publishing Year\")\n",
    "    fig.set_ylabel(emo.capitalize())\n",
    "    return fig\n",
    "\n",
    "plot_sentiment_time(articles_yrs, emo=\"trust\", rolling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
